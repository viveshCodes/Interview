Question No 1 :
In a competition, four different functions are observed. All the functions use a single for loop and within the for loop, the same set of statements are executed.
Consider the following for loops:
  A) for(i = 0; i < n; i++)
 
  B) for(i = 0; i < n; i += 2)
 
  C) for(i = 1; i < n; i *= 2)
 
  D) for(i = n; i > -1; i /= 2)
 
If n is the size of input(positive), which function is the most efficient? In other words, which loop completes the fastest.


Answer : C
The time complexity of the first for loop is O(n). 

The time complexity of the second for loop is O(n/2), equivalent to O(n) in asymptotic analysis. 

The time complexity of the third for loop is O(logn). 

The fourth for loop doesn't terminate. 



Question No 2 :
What is the time complexity of the following code :
       int a = 0, i = N;
        while (i > 0) {
            a += i;
            i /= 2;
        }
Approach :
Notice that in every iteration, i goes to i / 2
So, after x iterations, i will be N / 2^x
We have to find first x such that N / 2^x < 1 OR 2^x > N
Answer : log(N)
We have to find the smallest x such that `N / 2^x < 1 OR 2^x > N`

x = log(N) 





Question No 3 :
What is the time complexity of the following code :
       int j = 0;
        for(int i = 0; i < n; ++i) {
            while(j < n && arr[i] < arr[j]) {
                j++;
            }
        }
Approach :
In the first look, the time complexity seems to be O(n^2) due to two loops.
However, note that the variable j is not initialized for each value of variable i.
Answer : O(n)
Note that the variable j is not initialized for each value of variable i.
Hence, the inner j++ will be executed at most n times.
The i loop also runs n times.
So, the whole thing runs for O(n) times.


**Still not convinced ?**

Let's assume the array passed has its element in decreasing order. We will just dry run through the code :


Iteration 1 : i = 0, j = 0. arr[0] < arr[0] is false. So, the inner while loop breaks.
Iteration 2: i =1, j = 0. arr[1] < arr[0] is true. j becomes 1.
Iteration 3 : i = 1, j = 1. Condition false. We break. Note that j will remain 1 and is not reset back to 0.
Iteration 4 : i = 2, j = 1. arr[2] < arr[1]. True. j = 2.
Iteration 5 : i = 2, j = 2. Condition false. Break.
Iteration 6 : i = 3, j = 2. arr[3] < arr[2]. True. j = 3.
Iteration 7 : i = 3, j = 3. Condition false. Break.

As you can see, the inner while loop only runs once in this case.
So, total iterations is **2 * N.**
 

Question No 4 :
What is the time, space complexity of following code :
   int a = 0, b = 0;    
    for (i = 0; i < N; i++) {
        for (j = 0; j < N; j++) {
            a = a + j;
        }
    }
    for (k = 0; k < N; k++) {
        b = b + k;
    }

Approach :
Notice how the nested loop behaves. The j loop iterates for N times and the j loop itself is run N times.
So, the total number of runs would be N + N + …. N times
Answer : O(N * N) time, O(1) space
The first set of nested loops is O(N^2) and the second loop is O(N). 

This is O(max(N^2,N)) which is O(N^2). 
 

Question No 5 :
What is the time complexity of the following code :
   int a = 0;
    for (i = 0; i < N; i++) {
        for (j = N; j > i; j--) {
            a = a + i + j;
        }
    }

Approach :
Count the number of times the loop runs.
When i = 0, it runs for N times.
When i = 1, it runs for N - 1 times …
When i = k, it runs for N - k times
So, total number of runs = N + (N - 1) + (N - 2) + … 1 + 0 = ???
Answer : O(N^2)
Total number of runs = N + (N - 1) + (N - 2) + ... 1 + 0
= N * (N + 1) / 2
= 1/2 * N^2 + 1/2 * N
O(N^2) times. 





Question No 6 :
What does it mean when we say that an algorithm X is asymptotically more efficient than Y?

Answer :

 X will always be a better choice for large inputs

In asymptotic analysis we consider growth of algorithms in terms of input size. An algorithm X is said to be asymptotically better than Y if X takes smaller time than y for all input sizes n larger than a value n0 where n0 > 0.


Question No 7 :
What is time complexity of following code :
       int count = 0;
        for (int i = N; i > 0; i /= 2) {
            for (int j = 0; j < i; j++) {
                count += 1;
            }
        }
Answer : O(N)
In the first iteration, the j loop runs N times.

In the second iteration, the j loop runs N / 2 times. 

In the ith iteration, the j loop runs N / 2^i times. 

So, the total number of runs of loop = N + N / 2 + N / 4 + ... 1 

= **N * ( 1 + 1/2 + 1/4 + 1/8 + ... ) < 2 * N** 


Question No 8 :
What is the time complexity of the following code :
   int i, j, k = 0;
    for (i  = n/2; i <= n; i++) {
        for (j = 2; j <= n; j = j * 2) {
            k = k + n/2;
        }
    }

Answer : O(n logn )
Let's look at the code we are evaluating : 


int i, j, k = 0;
for (i = n/2; i <= n; i++) {
for (j = 2; j <= n; j = j * 2) {
k = k + n/2;
}
}

Now, let's just assume `n = 8` for now. 
We will try to see the values of j corresponding to each i. 

 
i = 4, j = 2, 4, 8
i = 5, j = 2, 4, 8
i = 6, j = 2, 4, 8
i = 7, j = 2, 4, 8
i = 8, j = 2, 4, 8

If you notice, j keeps doubling till it is less than or equal to n. Number of times, you can double a number till it is less than n would be log(n). 

Let's take more examples here to convince ourselves.


n = 16, j = 2, 4, 8, 16
n = 32, j = 2, 4, 8, 16, 32

So, j would run for O(log n) steps. 
i runs for n/2 steps. 

So, total steps ` = O (n/ 2 * log (n)) = O(n logn) `

 


Question No 9 :
In the following C++ function, let n >= m.
   int gcd(int n, int m) {
            if (n%m ==0) return m;
            if (n < m) swap(n, m);
            while (m > 0) {
                n = n%m;
                swap(n, m);
            }
            return n;
    }

What is the time complexity of the above function assuming n > m?

Answer : O(logN)
Let us say n = fibonacci(N) and m = fibonacci(N - 1)

fibonacci(N) = fibonacci(N-1) + fibonacci(N-2)

OR n = m + k where k < m. 

Therefore the step 

    n = n % m will make n = k
    
    swap(n, m) will result in
    
    n = fibonacci(N-1)
        
    m = k = fibonacci(N-2)
    
So, it will take N steps before m becomes 0.

This means, in the worst case, this algorithm can take N step if **n** is Nth fibonacci number. 

**Think of what's the relation between N and n**.


Question No 10 :
Which of the following is not bounded by O(n^2)?
    
 n^1.98
  (15^10) * n + 12099
 n^3 / (sqrt(n))
 (2^20) *N

Approach :
Look at the order of growth. Which
 function grows faster than O(n^2) ?


Answer : C
The order of growth of option (C) is n^2.5 which is higher than n^2.

Let's look at it with a different approach :


f(n) = O(n^2) if
f(n) <= C * n^2 for n > n0.

Let's look at every option one by one.

Option 1 :
(15^10) * n + 12099
Let's say C = 16^10
15^10 * n + 12099 < 16^10 * n^2 for n > 1.
So, it is O(n^2).

Option 2 : n^1.98
C = 1.
 n^1.98 < n^2 for n > 1.
So, its O(n^2) ```

Option 3 : n^3 / (sqrt(n)) or n^2.5
  There is no possible combination of C and n0 possible

Option 4 : 2^20 * n
   C = 2^20, n0 = 1
        2^20 * n <= 2^20 * n^2 for n > 1


Question No 11 :
Which of the given options provides the increasing order of complexity of functions f1, f2, f3 and f4:


f1(n) = 2^n
f2(n) = n^(3/2)
f3(n) = nLogn
f4(n) = n^(Logn)

Answer : f3, f2, f4, f1

f3, f2, f4, f1
 f3, f2, f1, f4
 f2, f3, f1, f4
 f2, f3, f4, f1
 
 
 
 
 
 






 
 
 
 
 




